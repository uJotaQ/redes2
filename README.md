
# PBL_REDES - Jogo R√≠tmico Distribu√≠do

**Autores**: Leonardo Oliveira Almeida da Cruz ([@oLeozito](https://github.com/oLeozito)) e Jo√£o Gabriel Santos Silva ([@uJotaQ](https://github.com/uJotaQ))
**Disciplina**: TEC502 - Redes e Conectividade (PBL)

Este projeto implementa um servidor de jogo multiplayer distribu√≠do, tolerante a falhas e escal√°vel, como parte da avalia√ß√£o da disciplina. O sistema foi projetado para migrar uma arquitetura de servidor de jogo centralizado para um cluster de n√≥s distribu√≠dos que gerenciam o estado do jogo de forma consistente.

---

## üöÄ Tecnologias Utilizadas

- **Go (Golang):** Linguagem principal para o desenvolvimento do servidor e cliente.  
- **Protocolo Raft:** Utilizado para consenso e replica√ß√£o de estado (via biblioteca `hashicorp/raft`).  
- **TCP Sockets:** Protocolo de comunica√ß√£o prim√°rio entre o cliente (`cliente.go`) e o n√≥ do servidor (`servidor.go`) ao qual ele se conecta.  
- **API REST (HTTP):** Protocolo de comunica√ß√£o *servidor-servidor*, usado para encaminhamento de requisi√ß√µes e broadcast de notifica√ß√µes.  
- **JSON:** Formato de serializa√ß√£o para todas as mensagens TCP e REST.  
- **Docker & Docker Compose:** Utilizado para orquestrar e testar o ambiente distribu√≠do com m√∫ltiplos n√≥s de servidor.

---

## üèõÔ∏è Vis√£o Geral da Arquitetura (Barema - Item 1)

A arquitetura do sistema √© baseada no padr√£o de **M√°quina de Estados Replicada (Replicated State Machine)**, utilizando o algoritmo de consenso Raft para garantir a consist√™ncia.

Diferente de uma arquitetura centralizada, onde um √∫nico servidor det√©m todo o estado (jogadores, salas, invent√°rios), esta solu√ß√£o utiliza um *cluster* de n√≥s `servidor.go`.

1. **N√≥s do Cluster:** Qualquer inst√¢ncia do `servidor.go` pode ser executada como um n√≥. Os n√≥s se comunicam para eleger um **L√≠der**.  
2. **L√≠der vs. Seguidor:**
   - O **L√≠der** √© o √∫nico n√≥ autorizado a aplicar mudan√ßas de estado (ex: cadastrar um jogador, comprar um pacote, jogar uma nota).  
   - Os **Seguidores (Followers)** atuam como *gateways* leves. Eles recebem conex√µes TCP dos clientes, mas, em vez de processar as l√≥gicas de neg√≥cio, eles **encaminham** a requisi√ß√£o para o L√≠der via API REST.  
3. **Fluxo de Dados (FSM):**
   - Um cliente (ex: `cliente1`) envia um comando (ex: `COMPRAR_PACOTE`) via TCP para o n√≥ ao qual est√° conectado (ex: `Servidor 2 - Seguidor`).  
   - O `Servidor 2` encaminha essa requisi√ß√£o para o `Servidor 1 - L√≠der` via REST (`/request-purchase`).  
   - O L√≠der recebe a requisi√ß√£o, a submete ao log do Raft (`raftNode.Apply()`).  
   - O Raft garante que este comando seja replicado e aplicado na **M√°quina de Estados Finitos (FSM)** de *todos* os n√≥s do cluster (incluindo o `Servidor 2`).  
   - A FSM (fun√ß√£o `FSM.Apply`) executa a l√≥gica de forma determin√≠stica, garantindo que o estoque de pacotes e o invent√°rio do jogador sejam atualizados de forma id√™ntica em todos os n√≥s.

Essa arquitetura permite **escalabilidade horizontal**: podemos adicionar mais n√≥s seguidores para lidar com mais conex√µes de clientes, sem sobrecarregar o n√≥ L√≠der, que se concentra apenas em orquestrar o estado.

---

## üìã Respostas Detalhadas ao Barema

### 2. Comunica√ß√£o Servidor-Servidor

A comunica√ß√£o entre os n√≥s do servidor √© realizada atrav√©s de duas vias principais:

1. **Raft (TCP):** O `hashicorp/raft` gerencia sua pr√≥pria comunica√ß√£o interna (bin√°ria) para elei√ß√£o de l√≠der e replica√ß√£o de log.  
2. **API REST (HTTP):** Uma API REST (`startHttpApi`) √© exposta por cada n√≥ para permitir a colabora√ß√£o e o encaminhamento de requisi√ß√µes.

**Endpoints REST Principais:**

- `/join`: (POST) Endpoint de *bootstrap*. Um novo n√≥ o utiliza para solicitar ao L√≠der sua adi√ß√£o ao cluster Raft.  
- `/request-register`, `/request-login`, `/request-logout`, `/request-reconnect`: (POST) Usados por seguidores para encaminhar comandos de autentica√ß√£o e sess√£o para o L√≠der.  
- `/request-purchase`, `/request-trade`: (POST) Usados por seguidores para encaminhar l√≥gicas de neg√≥cio cr√≠ticas (compra e troca) para o L√≠der.  
- `/request-create-room`, `/request-find-room`, `/request-play-note`: (POST) Usados por seguidores para encaminhar toda a l√≥gica de pareamento e jogabilidade para o L√≠der.  
- `/notify-player`: (POST) Endpoint crucial usado pelo L√≠der para **transmitir (broadcast)** eventos a *todos* os seguidores.

---

### 3. Comunica√ß√£o Cliente-Servidor

O barema sugere um modelo *publisher-subscriber*. A solu√ß√£o implementada atinge o *mesmo objetivo* (notifica√ß√µes *push* do servidor para o cliente) de forma mais integrada, usando uma combina√ß√£o de TCP e REST.

- **Canal Prim√°rio (TCP):** A comunica√ß√£o √© bidirecional sobre uma √∫nica conex√£o TCP (`handleConnection`).  
- **Modelo "Pub/Sub" Simulado (Push):**
  1. O L√≠der (Publisher) decide que um evento deve ocorrer (ex: `TURN_UPDATE`).  
  2. Ele **publica** este evento para todos os n√≥s seguidores via REST (`/notify-player`).  
  3. Cada n√≥ (Seguidor) verifica se o jogador-alvo est√° conectado a ele.  
  4. Se estiver, o n√≥ **envia (push)** a mensagem pela conex√£o TCP daquele cliente espec√≠fico.

Essa abordagem evita a necessidade de um *broker* externo, integrando o broadcast √† l√≥gica do Raft e usando o pr√≥prio TCP como canal de entrega.

---

### 4. Gerenciamento Distribu√≠do de Estoque

Este √© um dos pontos mais cr√≠ticos do sistema e √© resolvido integralmente pelo Raft.

> **Problema:** Como garantir que dois jogadores em servidores diferentes n√£o comprem o *mesmo* pacote √∫nico?

**Solu√ß√£o (Consenso do L√≠der):**

1. O "estoque global" (`packetStock`) √© um mapa replicado na FSM de todos os n√≥s.  
2. O L√≠der lineariza todas as requisi√ß√µes.  
3. A FSM processa uma de cada vez, garantindo exclusividade de item.  
4. O Raft garante que o log √© aplicado na mesma ordem em todos os n√≥s ‚Äî logo, dois jogadores nunca recebem o mesmo item.

---

### 5. Consist√™ncia e Justi√ßa do Estado do Jogo

Todo o estado do jogo (saldo, invent√°rios, progresso da partida) √© gerenciado pela FSM e protegido pelo Raft.

**Exemplo: Troca de Cartas (`PROPOSE_TRADE`):**

1. O jogador prop√µe uma troca.  
2. A FSM verifica se a oferta reversa existe.  
3. Se sim, executa a troca de forma **at√¥mica** ‚Äî sem inconsist√™ncias.  
4. Se n√£o, registra a proposta.

**Exemplo: Partida (`PLAY_NOTE_RAFT`):**

1. A FSM valida o turno do jogador.  
2. Atualiza a sequ√™ncia e o turno.  
3. O L√≠der √© a √∫nica fonte da verdade, garantindo consist√™ncia forte.

---

### 6. Pareamento em Ambiente Distribu√≠do

O pareamento funciona independentemente de onde os jogadores est√£o conectados, pois o "lobby" (`salasEmEspera` e `salas`) √© um estado replicado pela FSM.

1. Jogador 1 cria uma sala (FSM adiciona a `salasEmEspera`).  
2. Jogador 2 encontra e entra na sala.  
3. A FSM move a sala para `Em_Jogo`.  
4. O L√≠der notifica ambos os jogadores (um via REST ‚Üí TCP).

---

### 7. Toler√¢ncia a Falhas e Resili√™ncia

**Falha de Seguidor:** O cluster continua operando normalmente; clientes podem se reconectar a outro n√≥.  
**Falha de L√≠der:** Um novo L√≠der √© eleito automaticamente.  

**Reconex√£o de Cliente:**

1. O cliente tenta outro servidor da lista (`ReconnectLoop`).  
2. Envia `RECONNECT_SESSION` com seu login.  
3. O novo n√≥ vincula a sess√£o ativa ao socket rec√©m-criado.

---

## ‚öôÔ∏è Como Executar (Docker - Item 9)

O `docker-compose.yml` e o `Makefile` orquestram o ambiente distribu√≠do.

### 1. Construir e Iniciar o Cluster (3 N√≥s)

```bash
make all
# ou
docker-compose up --build -d
````

### 2. Visualizar os Logs

```bash
docker-compose logs -f
```

### 3. Escalar o Cluster

```bash
docker-compose up --build -d --scale servidor=5
```

### 4. Rodar o Cliente

```bash
go run ./cmd/cliente/cliente.go
```

### 5. Encerrar o Ambiente

```bash
make down
```

---

## üß™ Como Testar (Testes de Software - Item 8)

Foram desenvolvidos testes de integra√ß√£o automatizados (`cmd/servidor/servidor_test.go`) que validam o sistema em um cen√°rio realista.

**Para rodar os testes:**

```bash
cd cmd/servidor
go test -v -timeout 60s
```

**Resultado esperado:**

```
=== RUN   TestCadastroELogin
=== RUN   TestCadastroELogin/Cadastro
=== RUN   TestCadastroELogin/LoginCorreto
=== RUN   TestCadastroELogin/CadastroRepetido
=== RUN   TestCadastroELogin/LoginSenhaErrada
--- PASS: TestCadastroELogin (0.01s)
    --- PASS: TestCadastroELogin/Cadastro (0.00s)
    --- PASS: TestCadastroELogin/LoginCorreto (0.00s)
    --- PASS: TestCadastroELogin/CadastroRepetido (0.00s)
    --- PASS: TestCadastroELogin/LoginSenhaErrada (0.00s)
=== RUN   TestCompraPacote
=== RUN   TestCompraPacote/CompraComSaldo
=== RUN   TestCompraPacote/ChecarSaldoPosCompra
=== RUN   TestCompraPacote/EsgotarSaldo
--- PASS: TestCompraPacote (0.00s)
    --- PASS: TestCompraPacote/CompraComSaldo (0.00s)
    --- PASS: TestCompraPacote/ChecarSaldoPosCompra (0.00s)
    --- PASS: TestCompraPacote/EsgotarSaldo (0.00s)
=== RUN   TestPartidaSimples
=== RUN   TestPartidaSimples/CriarSala
=== RUN   TestPartidaSimples/EntrarSalaEIniciar
    servidor_test.go:497: Partida de um turno conclu√≠da com sucesso.
--- PASS: TestPartidaSimples (0.00s)
    --- PASS: TestPartidaSimples/CriarSala (0.00s)
    --- PASS: TestPartidaSimples/EntrarSalaEIniciar (0.00s)
PASS
ok      pbl_redes/server        1.234s
```

```

---

Quer que eu adicione um **sum√°rio com links internos (Table of Contents)** no in√≠cio do README tamb√©m? Isso deixaria a navega√ß√£o mais pr√°tica, especialmente se for entregue no GitHub.
```
