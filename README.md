Aqui est√° o README formatado em Markdown, pronto para voc√™ copiar e colar diretamente no seu arquivo `README.md`.

-----

# PBL\_REDES - Jogo R√≠tmico Distribu√≠do

**Autor**: Leonardo Oliveira Almeida da Cruz ([@oLeozito](https://www.google.com/search?q=https://github.com/oLeozito))
**Disciplina**: TEC502 - Redes e Conectividade (PBL)

Este projeto implementa um servidor de jogo multiplayer distribu√≠do, tolerante a falhas e escal√°vel, como parte da avalia√ß√£o da disciplina. O sistema foi projetado para migrar uma arquitetura de servidor de jogo centralizado para um cluster de n√≥s distribu√≠dos que gerenciam o estado do jogo de forma consistente.

## üöÄ Tecnologias Utilizadas

  * **Go (Golang):** Linguagem principal para o desenvolvimento do servidor e cliente.
  * **Protocolo Raft:** Utilizado para consenso e replica√ß√£o de estado (via biblioteca `hashicorp/raft`).
  * **TCP Sockets:** Protocolo de comunica√ß√£o prim√°rio entre o cliente (`cliente.go`) e o n√≥ do servidor (`servidor.go`) ao qual ele se conecta.
  * **API REST (HTTP):** Protocolo de comunica√ß√£o *servidor-servidor*, usado para encaminhamento de requisi√ß√µes e broadcast de notifica√ß√µes.
  * **JSON:** Formato de serializa√ß√£o para todas as mensagens TCP e REST.
  * **Docker & Docker Compose:** Utilizado para orquestrar e testar o ambiente distribu√≠do com m√∫ltiplos n√≥s de servidor.

-----

## üèõÔ∏è Vis√£o Geral da Arquitetura (Barema - Item 1)

A arquitetura do sistema √© baseada no padr√£o de **M√°quina de Estados Replicada (Replicated State Machine)**, utilizando o algoritmo de consenso Raft para garantir a consist√™ncia.

Diferente de uma arquitetura centralizada, onde um √∫nico servidor det√©m todo o estado (jogadores, salas, invent√°rios), esta solu√ß√£o utiliza um *cluster* de n√≥s `servidor.go`.

1.  **N√≥s do Cluster:** Qualquer inst√¢ncia do `servidor.go` pode ser executada como um n√≥. Os n√≥s se comunicam para eleger um **L√≠der**.
2.  **L√≠der vs. Seguidor:**
      * O **L√≠der** √© o √∫nico n√≥ autorizado a aplicar mudan√ßas de estado (ex: cadastrar um jogador, comprar um pacote, jogar uma nota).
      * Os **Seguidores (Followers)** atuam como *gateways* leves. Eles recebem conex√µes TCP dos clientes, mas, em vez de processar as l√≥gicas de neg√≥cio, eles **encaminham** a requisi√ß√£o para o L√≠der via API REST.
3.  **Fluxo de Dados (FSM):**
      * Um cliente (ex: `cliente1`) envia um comando (ex: `COMPRAR_PACOTE`) via TCP para o n√≥ ao qual est√° conectado (ex: `Servidor 2 - Seguidor`).
      * O `Servidor 2` encaminha essa requisi√ß√£o para o `Servidor 1 - L√≠der` via REST (`/request-purchase`).
      * O L√≠der recebe a requisi√ß√£o, a submete ao log do Raft (`raftNode.Apply()`).
      * O Raft garante que este comando seja replicado e aplicado na **M√°quina de Estados Finitos (FSM)** de *todos* os n√≥s do cluster (incluindo o `Servidor 2`).
      * A FSM (fun√ß√£o `FSM.Apply`) executa a l√≥gica de forma determin√≠stica, garantindo que o estoque de pacotes e o invent√°rio do jogador sejam atualizados de forma id√™ntica em todos os n√≥s.

Essa arquitetura permite **escalabilidade horizontal**: podemos adicionar mais n√≥s seguidores para lidar com mais conex√µes de clientes, sem sobrecarregar o n√≥ L√≠der, que se concentra apenas em orquestrar o estado.

-----

## üìã Respostas Detalhadas ao Barema

Aqui detalhamos como cada requisito de avalia√ß√£o foi implementado.

### [cite\_start]2. Comunica√ß√£o Servidor-Servidor [cite: 1]

A comunica√ß√£o entre os n√≥s do servidor √© realizada atrav√©s de duas vias principais:

1.  **Raft (TCP):** O `hashicorp/raft` gerencia sua pr√≥pria comunica√ß√£o interna (bin√°ria) para elei√ß√£o de l√≠der e replica√ß√£o de log.
2.  [cite\_start]**API REST (HTTP):** Uma API REST (`startHttpApi`) √© exposta por cada n√≥ para permitir a colabora√ß√£o e o encaminhamento de requisi√ß√µes[cite: 1].

[cite\_start]**Endpoints REST Principais:** [cite: 1]

  * `/join`: (POST) Endpoint de *bootstrap*. Um novo n√≥ o utiliza para solicitar ao L√≠der sua adi√ß√£o ao cluster Raft.
  * `/request-register`, `/request-login`, `/request-logout`, `/request-reconnect`: (POST) Usados por seguidores para encaminhar comandos de autentica√ß√£o e sess√£o para o L√≠der.
  * `/request-purchase`, `/request-trade`: (POST) Usados por seguidores para encaminhar l√≥gicas de neg√≥cio cr√≠ticas (compra e troca) para o L√≠der, garantindo que sejam processadas pela FSM.
  * `/request-create-room`, `/request-find-room`, `/request-play-note`: (POST) Usados por seguidores para encaminhar toda a l√≥gica de pareamento e jogabilidade para o L√≠der.
  * `/notify-player`: (POST) Endpoint crucial usado pelo L√≠der para **transmitir (broadcast)** eventos a *todos* os seguidores. Por exemplo, quando uma troca √© conclu√≠da, o L√≠der envia a notifica√ß√£o para este endpoint em todos os outros n√≥s, e cada n√≥ √© respons√°vel por verificar se o jogador-alvo est√° conectado a ele e entregar a mensagem via TCP.

### [cite\_start]3. Comunica√ß√£o Cliente-Servidor [cite: 1]

[cite\_start]O barema sugere um modelo *publisher-subscriber*[cite: 1]. A solu√ß√£o implementada atinge o *mesmo objetivo* (notifica√ß√µes *push* do servidor para o cliente) de forma mais integrada, usando uma combina√ß√£o de TCP e REST.

  * **Canal Prim√°rio (TCP):** A comunica√ß√£o √© bidirecional sobre uma √∫nica conex√£o TCP (`handleConnection`). O cliente envia comandos (ex: `PLAY_NOTE`) e o servidor responde diretamente (ex: `SCREEN_MSG` de erro).
  * **Modelo "Pub/Sub" Simulado (Push):** Para eventos que n√£o s√£o uma resposta direta (como o in√≠cio do turno do oponente ou uma proposta de troca), o sistema simula um Pub/Sub:
    1.  O L√≠der (Publisher) decide que um evento deve ocorrer (ex: `TURN_UPDATE`).
    2.  Ele **publica** este evento para todos os n√≥s seguidores via REST (usando o endpoint `/notify-player`).
    3.  Cada n√≥ (Seguidor) age como um *broker* local. Ele verifica se o jogador-alvo (Subscriber) est√° conectado a ele.
    4.  Se estiver, o n√≥ **envia (push)** a mensagem (`TURN_UPDATE`) pela conex√£o TCP daquele cliente espec√≠fico.

Esta abordagem evita a necessidade de um *broker* MQTT externo, integrando o *broadcast* de mensagens √† pr√≥pria l√≥gica de estado do Raft, e usando o TCP (que j√° √© usado para comandos) como o canal de entrega. [cite\_start]Nenhuma biblioteca de terceiros espec√≠fica para Pub/Sub foi usada, pois a funcionalidade foi implementada nativamente[cite: 1].

### [cite\_start]4. Gerenciamento Distribu√≠do de Estoque [cite: 1]

[cite\_start]Este √© um dos pontos mais cr√≠ticos do sistema e √© resolvido integralmente pelo Raft[cite: 1].

> [cite\_start]**Problema:** Como garantir que dois jogadores em servidores diferentes n√£o comprem o *mesmo* pacote √∫nico (ex: `packet_ID_001`) ao mesmo tempo? [cite: 1]

**Solu√ß√£o (Consenso do L√≠der):**

1.  O "estoque global" (`packetStock`) √© um mapa replicado na FSM de todos os n√≥s.
2.  Quando um Jogador 1 (no Servidor A) e um Jogador 2 (no Servidor B) tentam comprar um pacote simultaneamente, ambas as requisi√ß√µes s√£o encaminhadas para o **L√≠der**.
3.  O L√≠der **lineariza** (enfileira) essas requisi√ß√µes. Ele aplica uma de cada vez ao log do Raft.
4.  A FSM (no `case "COMPRAR_PACOTE"`) √© executada:
      * Ela bloqueia o estoque (`stockMu.Lock()`).
      * Pega o primeiro pacote dispon√≠vel (ex: `availablePacketIDs[0]`).
      * Marca o pacote como `Opened = true`.
      * Adiciona o pacote ao invent√°rio do jogador.
      * Desbloqueia o estoque.
5.  Quando a FSM processar a requisi√ß√£o do Jogador 2, o pacote que o Jogador 1 pegou n√£o estar√° mais dispon√≠vel. A FSM pegar√° o *pr√≥ximo* pacote da lista.

[cite\_start]Como o Raft garante que o log √© aplicado na mesma ordem em todos os lugares, √© **criptograficamente imposs√≠vel** que dois jogadores recebam o mesmo item, garantindo a justi√ßa e consist√™ncia do estoque[cite: 1].

### [cite\_start]5. Consist√™ncia e Justi√ßa do Estado do Jogo [cite: 1]

[cite\_start]Assim como o estoque, todo o estado do jogo (saldo, invent√°rios, progresso da partida) √© gerenciado pela FSM e protegido pelo Raft[cite: 1].

[cite\_start]**Exemplo: Troca de Cartas (`PROPOSE_TRADE`)** [cite: 1]
A l√≥gica de troca √© totalmente at√¥mica dentro da FSM:

1.  Um jogador (P1) prop√µe trocar a Carta A por uma Carta B de outro jogador (P2).
2.  A requisi√ß√£o √© enviada ao L√≠der e aplicada na FSM.
3.  A FSM verifica o mapa `activeTrades` para ver se (P2) j√° ofereceu a Carta B pela Carta A (uma `reverseTradeKey`).
4.  **Se a oferta reversa existe:** A FSM executa a troca *atomica e instantaneamente*. Ela remove a Carta A de P1, remove a Carta B de P2, e as adiciona aos invent√°rios opostos. Isso √© uma transa√ß√£o √∫nica.
5.  **Se n√£o existe:** A FSM apenas registra a oferta de P1 no mapa `activeTrades`.

**Exemplo: Partida (`PLAY_NOTE_RAFT`)**
O estado da partida (`GameState`) tamb√©m √© gerenciado pela FSM. Quando um jogador joga uma nota:

1.  A FSM verifica se √© o turno do jogador (`sala.Game.CurrentTurn == playerNum`).
2.  Ela adiciona a nota √† sequ√™ncia (`sala.Game.PlayedNotes`).
3.  Verifica se um ataque foi completado (`checkAttackCompletionFSM`).
4.  Atualiza o turno (`sala.Game.CurrentTurn = 2`).

Como o L√≠der Raft √© a √∫nica fonte da verdade para a ordem desses eventos, o estado do jogo √© sempre fortemente consistente.

### [cite\_start]6. Pareamento em Ambiente Distribu√≠do [cite: 1]

[cite\_start]O pareamento funciona independentemente de onde os jogadores est√£o conectados, pois o "lobby" (`salasEmEspera` e `salas`) √© um estado replicado pela FSM[cite: 1].

1.  **Cria√ß√£o (P√∫blica):** Jogador 1 (no Servidor A) envia `FIND_ROOM` (sem sala de espera). A requisi√ß√£o vai ao L√≠der, que aplica `CREATE_ROOM_RAFT`. A FSM adiciona uma nova sala ao mapa `salasEmEspera`.
2.  **Entrada (P√∫blica):** Jogador 2 (no Servidor B) envia `FIND_ROOM`. A requisi√ß√£o vai ao L√≠der. O L√≠der v√™ que `salasEmEspera` n√£o est√° vazio. Ele aplica `JOIN_ROOM_RAFT`.
3.  **L√≥gica do `JOIN_ROOM_RAFT` (na FSM):**
      * A FSM remove a sala de `salasEmEspera`.
      * Define o `Status` da sala como "Em\_Jogo".
      * Define `P2Login` como o Jogador 2.
      * Inicializa o `sala.Game`.
4.  **Notifica√ß√£o (Handler do L√≠der):**
      * Ap√≥s a FSM ser aplicada, o *handler HTTP* do L√≠der (ex: `handleJoinRoomResultREST`) √© notificado do sucesso.
      * Ele envia a mensagem `PAREADO` de volta ao Jogador 2 (pela resposta HTTP ao Servidor B).
      * Ele **difunde (broadcast)** a mensagem `PAREADO` para o Jogador 1 (via `/notify-player` para o Servidor A).

[cite\_start]A FSM garante que a sala seja preenchida apenas uma vez (pareamento √∫nico), e a camada HTTP/REST do L√≠der garante que ambos os jogadores (em servidores diferentes) sejam notificados[cite: 1].

### [cite\_start]7. Toler√¢ncia a Falhas e Resili√™ncia [cite: 1]

[cite\_start]O sistema √© resiliente a falhas de N√≥s (Servidores) e Clientes[cite: 1].

**Resili√™ncia a Falha de N√≥ (Servidor):**

  * **Falha de Seguidor:** Se um n√≥ seguidor falhar, o cluster continua operando normalmente. Os clientes conectados a ele perder√£o a conex√£o, mas poder√£o se reconectar a outro seguidor (veja abaixo).
  * **Falha de L√≠der:** Se o n√≥ L√≠der falhar, os seguidores restantes (desde que formem um qu√≥rum, ex: 2 de 3) ir√£o detectar a falha, iniciar uma nova elei√ß√£o e promover um novo L√≠der em milissegundos. O servi√ßo continua sem interrup√ß√£o.

**Resili√™ncia a Falha de Conex√£o (Cliente):**
O `cliente.go` foi projetado para sobreviver a falhas de conex√£o:

1.  **`connectToServer`:** O cliente possui uma lista de *todos* os endere√ßos de servidor. Ao iniciar, ele embaralha a lista e tenta se conectar a qualquer um deles.
2.  **`ReconnectLoop`:** Se a conex√£o TCP cair (ex: o n√≥ seguidor falhou), o `main()` do cliente entra em um loop, tentando se reconectar a *qualquer outro* n√≥ da lista.
3.  **`RECONNECT_SESSION`:** Ap√≥s reconectar (a um n√≥ diferente), o cliente envia o comando `RECONNECT_SESSION` com seu login. O servidor (L√≠der) recebe isso via FSM (`RECONNECT_SESSION_RAFT`), valida que o jogador estava `Online = true`, e o `handler` no *novo* n√≥ seguidor associa a *nova* conex√£o TCP ao estado do jogador (`player.Conn = conn`).

Isso permite que um jogador perca a conex√£o, se reconecte a um servidor totalmente diferente e continue sua sess√£o (e at√© mesmo seu jogo, se a l√≥gica fosse expandida) sem precisar fazer login novamente.

-----

## [cite\_start]‚öôÔ∏è Como Executar (Docker - Item 9) [cite: 1]

O `docker-compose.yml` e o `Makefile` orquestram o ambiente distribu√≠do.

**1. Construir e Iniciar o Cluster (3 N√≥s):**

O `docker-compose.yml` est√° configurado para iniciar 3 n√≥s de servidor e un√≠-los em um cluster.

```bash
# Constr√≥i as imagens e inicia os cont√™ineres
make all

# Ou, para iniciar em background:
docker-compose up --build -d
```

**2. Visualizar os Logs:**

Voc√™ ver√° os 3 servidores iniciando, realizando uma elei√ß√£o e um deles se declarando L√çDER.

```bash
docker-compose logs -f
```

**3. Escalar o Cluster:**

Para adicionar mais seguidores (escalabilidade):

```bash
docker-compose up --build -d --scale servidor=5
```

**4. Rodar o Cliente:**

O cliente n√£o est√° em Docker. Voc√™ pode rod√°-lo localmente no seu terminal:

```bash
# Estando na raiz do projeto (PBL_REDES/)
go run ./cmd/cliente/cliente.go
```

O cliente tentar√° se conectar √†s portas expostas pelos cont√™ineres Docker (ex: `8081`, `8082`, `8083`).

**5. Encerrar o Ambiente:**

```bash
make down
```

## [cite\_start]üß™ Como Testar (Testes de Software - Item 8) [cite: 1]

[cite\_start]Foram desenvolvidos testes de integra√ß√£o automatizados (`cmd/servidor/servidor_test.go`) que validam o sistema em um cen√°rio realista[cite: 1].

[cite\_start]O script de teste[cite: 1]:

1.  Compila e inicia um bin√°rio real do `servidor.go` como um n√≥ √∫nico (que se torna L√≠der).
2.  Espera ativamente que o servidor se torne L√çDER (consultando o endpoint `/health`).
3.  Inicia "clientes de teste" (`TestClient`) que se conectam via TCP.
4.  Executa os seguintes cen√°rios:
      * **`TestCadastroELogin`**: Testa o cadastro de um novo usu√°rio, o login bem-sucedido, a falha de cadastro duplicado e a falha de senha incorreta.
      * **`TestCompraPacote`**: Testa a compra de pacotes, a verifica√ß√£o de saldo (deve diminuir) e a falha de compra por saldo insuficiente (esgotamento).
      * **`TestPartidaSimples`**: Simula uma partida completa com dois jogadores, incluindo compra de instrumentos, sele√ß√£o, cria√ß√£o de sala, pareamento e uma rodada de jogo.

[cite\_start]**Para rodar os testes:** [cite: 1]

```bash
# 1. Navegue at√© o diret√≥rio do servidor
cd cmd/servidor

# 2. Execute o Go Test
# (O -v mostra os testes passando, e o -timeout √© por seguran√ßa)
go test -v -timeout 60s
```

**Resultado esperado:**

```
=== RUN   TestCadastroELogin
=== RUN   TestCadastroELogin/Cadastro
=== RUN   TestCadastroELogin/LoginCorreto
=== RUN   TestCadastroELogin/CadastroRepetido
=== RUN   TestCadastroELogin/LoginSenhaErrada
--- PASS: TestCadastroELogin (0.01s)
    --- PASS: TestCadastroELogin/Cadastro (0.00s)
    --- PASS: TestCadastroELogin/LoginCorreto (0.00s)
    --- PASS: TestCadastroELogin/CadastroRepetido (0.00s)
    --- PASS: TestCadastroELogin/LoginSenhaErrada (0.00s)
=== RUN   TestCompraPacote
=== RUN   TestCompraPacote/CompraComSaldo
=== RUN   TestCompraPacote/ChecarSaldoPosCompra
=== RUN   TestCompraPacote/EsgotarSaldo
--- PASS: TestCompraPacote (0.00s)
    --- PASS: TestCompraPacote/CompraComSaldo (0.00s)
    --- PASS: TestCompraPacote/ChecarSaldoPosCompra (0.00s)
    --- PASS: TestCompraPacote/EsgotarSaldo (0.00s)
=== RUN   TestPartidaSimples
=== RUN   TestPartidaSimples/CriarSala
=== RUN   TestPartidaSimples/EntrarSalaEIniciar
    servidor_test.go:497: Partida de um turno conclu√≠da com sucesso.
--- PASS: TestPartidaSimples (0.00s)
    --- PASS: TestPartidaSimples/CriarSala (0.00s)
    --- PASS: TestPartidaSimples/EntrarSalaEIniciar (0.00s)
PASS
ok      pbl_redes/server        1.234s
```
